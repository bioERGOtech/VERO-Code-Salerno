{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "758ba29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:86: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  p1 = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  p2 = pd.to_datetime(s, errors=\"coerce\", dayfirst=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:86: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  p1 = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  p2 = pd.to_datetime(s, errors=\"coerce\", dayfirst=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:86: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  p1 = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  p2 = pd.to_datetime(s, errors=\"coerce\", dayfirst=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:86: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  p1 = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  p2 = pd.to_datetime(s, errors=\"coerce\", dayfirst=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:86: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  p1 = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  p2 = pd.to_datetime(s, errors=\"coerce\", dayfirst=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:86: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  p1 = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  p2 = pd.to_datetime(s, errors=\"coerce\", dayfirst=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:86: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  p1 = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  p2 = pd.to_datetime(s, errors=\"coerce\", dayfirst=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:86: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  p1 = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:86: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  p1 = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:86: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  p1 = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  p2 = pd.to_datetime(s, errors=\"coerce\", dayfirst=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:87: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  p2 = pd.to_datetime(s, errors=\"coerce\", dayfirst=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:86: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  p1 = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:86: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  p1 = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  p2 = pd.to_datetime(s, errors=\"coerce\", dayfirst=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:87: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  p2 = pd.to_datetime(s, errors=\"coerce\", dayfirst=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:86: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  p1 = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:86: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  p1 = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:86: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  p1 = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:87: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  p2 = pd.to_datetime(s, errors=\"coerce\", dayfirst=False)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:87: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  p2 = pd.to_datetime(s, errors=\"coerce\", dayfirst=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"age_at_observation_start\"] = ((df[\"observation_start_date\"] - df[\"birth_date\"]).dt.days / 365.25).round(2)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:153: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"observation_length_days_calc\"] = (df[\"observation_end_date\"] - df[\"observation_start_date\"]).dt.days\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18724\\1918969558.py:195: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  df.to_excel(OUT_PATH, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Standardization complete.\n",
      "Saved to: C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\outputs\\standardization\\standardized_dataset.xlsx\n",
      "Rows: 403 | Columns: 137\n",
      "Numeric columns: 37\n",
      "Date columns: 14\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# 02 - STANDARDIZATION\n",
    "# - Clean text tokens and unify missing markers\n",
    "# - Normalize key categorical labels (e.g., gender)\n",
    "# - Robust date parsing (handles strings, Excel serials, tz)\n",
    "# - Soft numeric coercion for mostly-numeric object columns\n",
    "# - Derive useful variables (age_at_observation_start, observation_length_days_calc, smoking_pack_index_like)\n",
    "# - Drop duplicate patient_id rows (keep first)\n",
    "# - Save standardized dataset\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ------------------ CONFIG ------------------\n",
    "INPUT_PATH = \"C:/Users/HP/OneDrive/Desktop/VERO_code/Phase_1/data/processed/merged_codige_wide_english_values_translated.xlsx\"\n",
    "OUT_DIR = r\"C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\outputs\\standardization\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------ LOAD ------------------\n",
    "df = pd.read_excel(INPUT_PATH)\n",
    "\n",
    "# ------------------ 1) BASIC STRING CLEANUPS ------------------\n",
    "# - Trim whitespace\n",
    "# - Normalize common missing tokens to np.nan\n",
    "# - Unify \"Missing\" phrasing for later visuals\n",
    "missing_aliases = {\n",
    "    \"nan\": np.nan, \"NaN\": np.nan, \"NONE\": np.nan, \"None\": np.nan, \"\": np.nan,\n",
    "    \"missing\": \"Missing / Not Known\", \"Missing\": \"Missing / Not Known\",\n",
    "    \"Non noto\": \"Missing / Not Known\", \"non noto\": \"Missing / Not Known\",\n",
    "    \"Non noto / Non conosciuto\": \"Missing / Not Known\",\n",
    "    \"Non disponibile\": \"Missing / Not Known\",\n",
    "}\n",
    "\n",
    "obj_like = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "for c in obj_like:\n",
    "    # Work in string space to avoid .str errors\n",
    "    s = df[c].astype(str).str.strip()\n",
    "    # Replace explicit tokens\n",
    "    s = s.replace(missing_aliases)\n",
    "    # Collapse strings that are literally \"nan\" (created by astype(str) on NaN)\n",
    "    s = s.replace({\"NaT\": np.nan, \"NaN\": np.nan, \"None\": np.nan, \"nan\": np.nan})\n",
    "    # If everything became \"\" after strip, set to NaN\n",
    "    s = s.replace({\"\": np.nan})\n",
    "    df[c] = s\n",
    "\n",
    "# ------------------ 2) KEY CATEGORICAL NORMALIZATION ------------------\n",
    "# Gender (defensive): unify various forms to \"Male\"/\"Female\"\n",
    "if \"gender\" in df.columns:\n",
    "    df[\"gender\"] = (\n",
    "        df[\"gender\"]\n",
    "        .replace({\n",
    "            \"1\": \"Male\", \"2\": \"Female\",\n",
    "            \"Maschio\": \"Male\", \"Femmina\": \"Female\",\n",
    "            \"M\": \"Male\", \"F\": \"Female\",\n",
    "            \"male\": \"Male\", \"female\": \"Female\",\n",
    "        })\n",
    "        .where(df[\"gender\"].notna(), other=np.nan)\n",
    "    )\n",
    "\n",
    "# If you need other categorical normalizations, add here:\n",
    "# e.g., yes/no variants → Present/Absent\n",
    "binary_alias_map = {\n",
    "    \"si\": \"Present / Yes\",\n",
    "    \"sì\": \"Present / Yes\",\n",
    "    \"yes\": \"Present / Yes\",\n",
    "    \"no\": \"Absent / No\",\n",
    "}\n",
    "for c in obj_like:\n",
    "    # Only apply to small-cardinality columns (avoid damaging free text)\n",
    "    if df[c].nunique(dropna=True) <= 6:\n",
    "        df[c] = df[c].astype(str).str.lower().replace(binary_alias_map)\n",
    "        df[c] = df[c].replace({\"present / yes\": \"Present / Yes\", \"absent / no\": \"Absent / No\"})\n",
    "\n",
    "# ------------------ 3) ROBUST DATE PARSING ------------------\n",
    "def parse_to_datetime_series_strict(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Robustly coerce a series to datetime64[ns] with NaT for failures.\n",
    "    - Tries parsing with dayfirst=True and dayfirst=False, then combines.\n",
    "    - Converts Excel serial numbers to dates (origin 1899-12-30).\n",
    "    - Normalizes any timezone-aware stamps to naive.\n",
    "    \"\"\"\n",
    "    # First passes: strings, existing datetimes\n",
    "    p1 = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
    "    p2 = pd.to_datetime(s, errors=\"coerce\", dayfirst=False)\n",
    "\n",
    "    # Excel serials\n",
    "    numeric = pd.to_numeric(s, errors=\"coerce\")\n",
    "    serial_dt = pd.Series(pd.NaT, index=s.index, dtype=\"datetime64[ns]\")\n",
    "    mask = numeric.notna()\n",
    "    if mask.any():\n",
    "        serial_dt.loc[mask] = pd.to_datetime(\"1899-12-30\") + pd.to_timedelta(numeric.loc[mask], unit=\"D\")\n",
    "\n",
    "    parsed = p1.combine_first(p2).combine_first(serial_dt)\n",
    "\n",
    "    # Normalize timezone (if any) to naive\n",
    "    try:\n",
    "        parsed = parsed.dt.tz_convert(None)\n",
    "    except Exception:\n",
    "        try:\n",
    "            parsed = parsed.dt.tz_localize(None)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    parsed = pd.to_datetime(parsed, errors=\"coerce\")\n",
    "    return parsed\n",
    "\n",
    "date_candidates = [c for c in df.columns if c.lower().endswith(\"_date\") or c.lower().endswith(\"_dt\") or (\"date\" in c.lower())]\n",
    "for c in date_candidates:\n",
    "    df[c] = parse_to_datetime_series_strict(df[c])\n",
    "\n",
    "# ------------------ 4) SOFT NUMERIC COERCION (ROBUST) ------------------\n",
    "# Identify object-like columns that are \"mostly numeric-looking\" (including commas as decimal separators),\n",
    "# skip obvious ID-like columns, and coerce them to real numbers.\n",
    "\n",
    "id_like_cols = {\"patient_id\"}  # extend if needed (e.g., {'patient_id','mrn','internal_id'})\n",
    "obj_or_cat = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "coerced_cols = []\n",
    "\n",
    "for c in obj_or_cat:\n",
    "    if c in id_like_cols:\n",
    "        continue\n",
    "    s = df[c]\n",
    "    non_null = s.dropna()\n",
    "    if non_null.empty:\n",
    "        continue\n",
    "\n",
    "    s_str = non_null.astype(str)\n",
    "\n",
    "    # Heuristic: if many letters, likely categorical text (skip)\n",
    "    alpha_ratio = s_str.str.contains(r\"[A-Za-z]\", regex=True).mean()\n",
    "    if alpha_ratio > 0.20:\n",
    "        continue\n",
    "\n",
    "    # Try numeric probe (replace comma decimal to dot)\n",
    "    s_num_probe = pd.to_numeric(s_str.str.replace(\",\", \".\", regex=False), errors=\"coerce\")\n",
    "    if s_num_probe.notna().mean() > 0.80:  # mostly numeric-like\n",
    "        df[c] = pd.to_numeric(df[c].astype(str).str.replace(\",\", \".\", regex=False), errors=\"coerce\")\n",
    "        coerced_cols.append(c)\n",
    "\n",
    "if coerced_cols:\n",
    "    print(\"Soft-coerced to numeric:\", coerced_cols)\n",
    "\n",
    "# ------------------ 5) DERIVED VARIABLES ------------------\n",
    "# 5.1 age_at_observation_start\n",
    "if {\"birth_date\", \"observation_start_date\"}.issubset(df.columns):\n",
    "    df[\"age_at_observation_start\"] = ((df[\"observation_start_date\"] - df[\"birth_date\"]).dt.days / 365.25).round(2)\n",
    "\n",
    "# 5.2 observation_length_days_calc (from dates)\n",
    "if {\"observation_start_date\", \"observation_end_date\"}.issubset(df.columns):\n",
    "    df[\"observation_length_days_calc\"] = (df[\"observation_end_date\"] - df[\"observation_start_date\"]).dt.days\n",
    "\n",
    "# 5.3 smoking_pack_index_like (simple proxy)\n",
    "if {\"cigarettes_per_day\", \"smoking_years\"}.issubset(df.columns):\n",
    "    df[\"smoking_pack_index_like\"] = df[\"cigarettes_per_day\"].fillna(0) * df[\"smoking_years\"].fillna(0)\n",
    "\n",
    "# ------------------ 6) DUPLICATES (CONSERVATIVE) ------------------\n",
    "# Keep the first occurrence of each patient_id (if exists). If you need aggregation, change strategy here.\n",
    "if \"patient_id\" in df.columns:\n",
    "    before = len(df)\n",
    "    df = df.drop_duplicates(subset=[\"patient_id\"], keep=\"first\")\n",
    "    after = len(df)\n",
    "    if before - after > 0:\n",
    "        print(f\"Dropped {before - after} duplicate patient_id rows (kept first).\")\n",
    "\n",
    "# ------------------ 7) SAVE ------------------\n",
    "OUT_PATH = os.path.join(OUT_DIR, \"standardized_dataset.xlsx\")\n",
    "\n",
    "# ------------------ TZ STRIP + COERCE TO DATE (YYYY-MM-DD) ------------------\n",
    "import pandas as pd\n",
    "\n",
    "def strip_tz_and_to_date(s: pd.Series) -> pd.Series:\n",
    "    # Ensure datetime dtype where possible\n",
    "    s = pd.to_datetime(s, errors=\"coerce\")\n",
    "\n",
    "    # Remove any timezone if present\n",
    "    try:\n",
    "        s = s.dt.tz_convert(None)\n",
    "    except Exception:\n",
    "        try:\n",
    "            s = s.dt.tz_localize(None)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return pd.to_datetime(s.dt.date, errors=\"coerce\")\n",
    "\n",
    "# Find datetime-like columns after your parsing step\n",
    "dt_cols = [c for c in df.columns if pd.api.types.is_datetime64_any_dtype(df[c])]\n",
    "for c in dt_cols:\n",
    "    df[c] = strip_tz_and_to_date(df[c])\n",
    "\n",
    "\n",
    "df.to_excel(OUT_PATH, index=False)\n",
    "\n",
    "print(\"✅ Standardization complete.\")\n",
    "print(\"Saved to:\", OUT_PATH)\n",
    "\n",
    "# Optional: quick sanity snapshot\n",
    "print(\"Rows:\", len(df), \"| Columns:\", df.shape[1])\n",
    "num_cols = df.select_dtypes(include=\"number\").columns\n",
    "print(\"Numeric columns:\", len(num_cols))\n",
    "print(\"Date columns:\", sum(pd.api.types.is_datetime64_any_dtype(df[c]) for c in df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3d2f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
