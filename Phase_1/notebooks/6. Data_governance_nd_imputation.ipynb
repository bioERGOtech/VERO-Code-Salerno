{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d246adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset and action plan\n",
    "data_path = r\"C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\data\\processed\\merged_codige_wide_english_values_translated.xlsx\"\n",
    "action_plan_path = r\"C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\outputs\\recommendations\\variable_action_plan.xlsx\"\n",
    "\n",
    "# Load the cleaned data\n",
    "df = pd.read_excel(data_path)\n",
    "\n",
    "# Load the variable action plan\n",
    "action_plan_df = pd.read_excel(action_plan_path, sheet_name=\"action_plan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6cfdcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-priority variables: ['breast_cancer_subtype', 'radiotherapy_end_date', 'prior_radiotherapy', 'radiotherapy_start_date', 'colon_cancer_location', 'hospital_discharge_date', 'ejection_fraction_percent', 'ejection_fraction_category', 'hospital_admission_date', 'gamma_gt_range', 'albumin_range', 'azotemia_range', 'adr_ctcae_grade', 'tumor_stage_roman', 'blood_glucose_range', 'direct_bilirubin_range', 'total_bilirubin_range', 'creatinine_range', 'ast_got_range', 'alt_gpt_range', 'white_blood_cells_range', 'neutrophils_percent_range', 'platelet_count_range', 'dpyd_genotype_type', 'red_blood_cells_range', 'hemoglobin_range', 'ethnicity', 'bmi_value', 'bmi_category', 'dpyd_genotype_known', 'chemo_cycles_n', 'age', 'age_group', 'gender', 'observation_start_date', 'observation_end_date', 'tumor_type', 'oncology_treatment_lines_n', 'transfusion_received', 'transfusions_total_n', 'hypertension', 'aortic_insufficiency', 'dyslipidemia', 'bph', 'obesity_comorbidity', 'ischemic_heart_disease', 'atrial_fibrillation', 'copd', 'asthma', 'diabetes_type_ii', 'renal_insufficiency', 'depressive_syndrome', 'anemia_comorbidity', 'psychiatric_disorders', 'cardiovascular_disorders', 'gastrointestinal_disorders', 'cerebrovascular_disorders', 'adr_n_grado3', 'adr_n_grado4', 'adr_n_grado5', 'death_date', 'end_reason_progression_any_line', 'dose_reduced', 'active_principles_n']\n"
     ]
    }
   ],
   "source": [
    "# Filter high-priority variables from the action plan\n",
    "high_priority_vars = action_plan_df[action_plan_df['priority'] == 'high']['variable'].tolist()\n",
    "\n",
    "# Extract high-priority variables from the dataframe\n",
    "high_priority_df = df[high_priority_vars]\n",
    "\n",
    "# Display high-priority variables\n",
    "print(f\"High-priority variables: {high_priority_vars}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c85475e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         missing_count  missing_percentage\n",
      "breast_cancer_subtype              402           99.751861\n",
      "radiotherapy_end_date              370           91.811414\n",
      "prior_radiotherapy                 368           91.315136\n",
      "radiotherapy_start_date            368           91.315136\n",
      "death_date                         306           75.930521\n",
      "...                                ...                 ...\n",
      "observation_end_date                 0            0.000000\n",
      "observation_start_date               0            0.000000\n",
      "gender                               0            0.000000\n",
      "age                                  0            0.000000\n",
      "active_principles_n                  0            0.000000\n",
      "\n",
      "[64 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check missingness for high-priority variables\n",
    "missing_high_priority = high_priority_df.isna().sum()\n",
    "missing_high_priority_pct = (missing_high_priority / len(df)) * 100\n",
    "\n",
    "# Display missingness summary\n",
    "missing_high_priority_summary = pd.DataFrame({\n",
    "    'missing_count': missing_high_priority,\n",
    "    'missing_percentage': missing_high_priority_pct\n",
    "}).sort_values(by='missing_percentage', ascending=False)\n",
    "\n",
    "print(missing_high_priority_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "359d113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply imputation based on column type and action plan\n",
    "def apply_imputation(df, action_plan_df):\n",
    "    # Iterate through all high-priority columns\n",
    "    for col in high_priority_vars:\n",
    "        # Get the recommended action for the column from the action plan\n",
    "        action = action_plan_df[action_plan_df['variable'] == col]['recommended_action'].values[0]\n",
    "\n",
    "        # Check if the recommended action is 'Impute' and handle imputation based on column type\n",
    "        if action == 'Impute':\n",
    "            # For categorical variables, impute with the mode (most frequent value)\n",
    "            if df[col].dtype == 'object':\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "                print(f\"Imputed {col} with mode (categorical variable)\")\n",
    "\n",
    "            # For numeric variables, impute with the median value\n",
    "            elif df[col].dtype in ['int64', 'float64']:\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "                print(f\"Imputed {col} with median (numeric variable)\")\n",
    "\n",
    "            # You can add any additional rules for other variable types as needed\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the imputation function\n",
    "df = apply_imputation(df, action_plan_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76f52cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns with > 40% missing data, except 'death_date': ['breast_cancer_subtype', 'radiotherapy_end_date', 'prior_radiotherapy', 'radiotherapy_start_date', 'colon_cancer_location', 'hospital_discharge_date', 'ejection_fraction_percent', 'ejection_fraction_category', 'hospital_admission_date', 'gamma_gt_range', 'albumin_range', 'azotemia_range']\n"
     ]
    }
   ],
   "source": [
    "# Handle columns with high missingness (drop or special handling)\n",
    "high_missing_columns = missing_high_priority_pct[missing_high_priority_pct > 40].index.tolist()\n",
    "\n",
    "# Ensure that 'death_date' is NOT dropped, even if it has > 40% missing values\n",
    "if 'death_date' in high_missing_columns:\n",
    "    high_missing_columns.remove('death_date', )\n",
    "    # Impute missing 'death_date' values with a placeholder date (12/31/2099)\n",
    "    df['death_date'] = df['death_date'].fillna(pd.to_datetime('2099-12-31'))\n",
    "\n",
    "# Drop other columns with > 40% missing data\n",
    "df.drop(columns=high_missing_columns, inplace=True)\n",
    "\n",
    "print(f\"Dropped columns with > 40% missing data, except 'death_date': {high_missing_columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc28533c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10064\\4293959988.py:5: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  df.to_excel(output_path, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned dataset has been saved successfully at: C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\data\\processed\\cleaned_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define the output path where the cleaned data will be saved\n",
    "output_path = r\"C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\data\\processed\\cleaned_data.xlsx\"\n",
    "\n",
    "# Export the cleaned DataFrame to an Excel file\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Cleaned dataset has been saved successfully at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c97f735e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Missingness summary has been saved successfully at: C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\data\\raw\\missingness_summary.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10064\\3637318986.py:21: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  missing_summary.to_excel(output_path, index=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the action plan that contains priority levels and recommended actions\n",
    "action_plan_path = r\"C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\outputs\\recommendations\\variable_action_plan.xlsx\"\n",
    "action_plan_df = pd.read_excel(action_plan_path, sheet_name=\"action_plan\")\n",
    "\n",
    "# Create a missingness summary for the cleaned data (df)\n",
    "missing_summary = pd.DataFrame({\n",
    "    \"variable\": df.columns,\n",
    "    \"missing_count\": df.isna().sum(),\n",
    "    \"missing_pct\": (df.isna().mean() * 100).round(2),\n",
    "    \"type\": [df[col].dtype for col in df.columns]\n",
    "})\n",
    "\n",
    "# Merge the missingness summary with the action plan to get 'role', 'priority', and 'recommended_action'\n",
    "missing_summary = missing_summary.merge(action_plan_df[['variable', 'role', 'priority', 'recommended_action']], \n",
    "                                         how='left', on='variable')\n",
    "\n",
    "# Export the summary as a new Excel file\n",
    "output_path = r\"C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\data\\raw\\missingness_summary.xlsx\"\n",
    "missing_summary.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Missingness summary has been saved successfully at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "691d8cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns with >= 40% missing data: ['smoking_years', 'tumor_stage_tnm', 'histological_grade', 'surgery_date', 'surgery_type', 'surgery_type_specify', 'prior_surgery', 'surgery_complications', 'reoperation_for_complication', 'hospitalization_for_surgery_complication', 'treatment_line_n', 'chemo_schema_end_reason', 'toxicity_type', 'ricovero_n', 'admission_diagnosis', 'discharge_diagnosis', 'admission_mode', 'er_stay_duration', 'tipo_left', 'hospitalization_cause', 'oncology_schema_modified', 'comorbilita_cat', 'altro', 'adr_onset_date', 'hospitalization_type', 'adr_chemo_correlation', 'adr_description_clean']\n"
     ]
    }
   ],
   "source": [
    "# Calculate missing percentages for each column\n",
    "missing_pct = df.isna().mean() * 100\n",
    "\n",
    "# Identify columns with >= 40% missing data\n",
    "columns_to_drop = missing_pct[missing_pct >= 40].index.tolist()\n",
    "\n",
    "# Drop the identified columns\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Print the dropped columns for reference\n",
    "print(f\"Dropped columns with >= 40% missing data: {columns_to_drop}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0db1f478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after imputation: ethnicity                      5\n",
      "education_level                5\n",
      "bmi_value                      5\n",
      "bmi_category                   5\n",
      "employment_status              5\n",
      "alcohol_consumption            5\n",
      "smoking_status_binary        134\n",
      "smoking_status_detail          5\n",
      "tumor_diagnosis_date          25\n",
      "oncology_unit_start_date     148\n",
      "tumor_stage_roman            135\n",
      "dpyd_genotype_known            4\n",
      "dpyd_genotype_type            61\n",
      "blood_glucose_range          126\n",
      "white_blood_cells_range       66\n",
      "red_blood_cells_range         61\n",
      "hemoglobin_range              61\n",
      "neutrophils_percent_range     66\n",
      "platelet_count_range          65\n",
      "creatinine_range              78\n",
      "ast_got_range                 68\n",
      "alt_gpt_range                 68\n",
      "total_bilirubin_range         90\n",
      "direct_bilirubin_range       111\n",
      "chemo_schema_name              1\n",
      "chemo_schema_end_date          2\n",
      "chemo_cycles_n                 2\n",
      "comorbidita                  156\n",
      "data                         156\n",
      "comorbidity_category_list    160\n",
      "altre_pat_n                  160\n",
      "adr_description              144\n",
      "adr_ctcae_grade              145\n",
      "adr_outcome                  160\n",
      "adr_chemo_action             158\n",
      "adr_source_project           144\n",
      "adr_macro_category           144\n",
      "adr_clean.1                  144\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the action plan that contains priority levels and recommended actions\n",
    "action_plan_path = r\"C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\outputs\\recommendations\\variable_action_plan.xlsx\"\n",
    "action_plan_df = pd.read_excel(action_plan_path, sheet_name=\"action_plan\")\n",
    "\n",
    "# Loop through each column in the cleaned DataFrame\n",
    "for col in df.columns:\n",
    "    # Check if there are missing values in the column\n",
    "    if df[col].isna().sum() > 0:\n",
    "        \n",
    "        # Get the recommended action for the column from the action plan\n",
    "        action = action_plan_df[action_plan_df['variable'] == col]['recommended_action'].values[0]\n",
    "        \n",
    "        # Impute based on the recommended action\n",
    "        if action == 'Impute':\n",
    "            # Check if the column is categorical\n",
    "            if df[col].dtype == 'object':\n",
    "                # Impute missing values with the mode (most frequent value) for categorical columns\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "                print(f\"Imputed {col} using mode (for categorical variable)\")\n",
    "\n",
    "            # For numeric columns, impute with the median\n",
    "            elif df[col].dtype in ['int64', 'float64']:\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "                print(f\"Imputed {col} using median (for numeric variable)\")\n",
    "\n",
    "            # You can add any additional rules for other variable types as needed\n",
    "\n",
    "# Check the result of the imputation\n",
    "missing_after_imputation = df.isna().sum()\n",
    "print(f\"Missing values after imputation: {missing_after_imputation[missing_after_imputation > 0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19f2b4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after advanced imputation: ethnicity                      5\n",
      "education_level                5\n",
      "bmi_value                      5\n",
      "bmi_category                   5\n",
      "employment_status              5\n",
      "alcohol_consumption            5\n",
      "smoking_status_binary        134\n",
      "smoking_status_detail          5\n",
      "tumor_diagnosis_date          25\n",
      "oncology_unit_start_date     148\n",
      "tumor_stage_roman            135\n",
      "dpyd_genotype_known            4\n",
      "dpyd_genotype_type            61\n",
      "blood_glucose_range          126\n",
      "white_blood_cells_range       66\n",
      "red_blood_cells_range         61\n",
      "hemoglobin_range              61\n",
      "neutrophils_percent_range     66\n",
      "platelet_count_range          65\n",
      "creatinine_range              78\n",
      "ast_got_range                 68\n",
      "alt_gpt_range                 68\n",
      "total_bilirubin_range         90\n",
      "direct_bilirubin_range       111\n",
      "chemo_schema_name              1\n",
      "chemo_schema_end_date          2\n",
      "chemo_cycles_n                 2\n",
      "comorbidita                  156\n",
      "data                         156\n",
      "comorbidity_category_list    160\n",
      "altre_pat_n                  160\n",
      "adr_description              144\n",
      "adr_ctcae_grade              145\n",
      "adr_outcome                  160\n",
      "adr_chemo_action             158\n",
      "adr_source_project           144\n",
      "adr_macro_category           144\n",
      "adr_clean.1                  144\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10064\\2771492840.py:50: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  df.to_excel(output_path, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Advanced imputation complete and saved to: C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\data\\interim\\advanced_imputed_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fancyimpute import IterativeImputer, KNN\n",
    "\n",
    "# Load the action plan\n",
    "action_plan_path = r\"C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\outputs\\recommendations\\variable_action_plan.xlsx\"\n",
    "\n",
    "action_plan_df = pd.read_excel(action_plan_path, sheet_name=\"action_plan\")\n",
    "\n",
    "# Function to apply Bayesian or KNN imputation based on action plan\n",
    "def apply_advanced_imputation(df, action_plan_df):\n",
    "    for col in df.columns:\n",
    "        if df[col].isna().sum() > 0:  # Check if the column has missing values\n",
    "            # Get the recommended action for the column from the action plan\n",
    "            action = action_plan_df[action_plan_df['variable'] == col]['recommended_action'].values[0]\n",
    "            \n",
    "            if action == 'Impute':\n",
    "                # Check if Bayesian imputation is recommended\n",
    "                bayesian_action = action_plan_df[action_plan_df['variable'] == col]['imputation_method'].values[0]\n",
    "                \n",
    "                if bayesian_action == 'Bayesian' and df[col].dtype in ['int64', 'float64']:\n",
    "                    # Apply Bayesian imputation using fancyimpute's IterativeImputer (which uses Bayesian Ridge)\n",
    "                    bayesian_imputer = IterativeImputer(estimator='bayesian_ridge', random_state=42)\n",
    "                    df[col] = bayesian_imputer.fit_transform(df[[col]])  # Apply Bayesian Ridge\n",
    "                    print(f\"Imputed {col} using Bayesian Ridge (numeric variable)\")\n",
    "                \n",
    "                # Check for KNN imputation if recommended or if Bayesian is not an option\n",
    "                elif bayesian_action != 'Bayesian' and df[col].dtype in ['int64', 'float64']:\n",
    "                    knn_imputer = KNN(k=5)  # Set number of neighbors for KNN imputation\n",
    "                    df[col] = knn_imputer.fit_transform(df[[col]])  # Apply KNN imputation\n",
    "                    print(f\"Imputed {col} using KNN (numeric variable)\")\n",
    "                \n",
    "                # For categorical variables, if KNN or Bayesian is recommended\n",
    "                elif df[col].dtype == 'object':\n",
    "                    knn_imputer = KNN(k=5)\n",
    "                    df[col] = knn_imputer.fit_transform(df[[col]]).astype(str)  # KNN for categorical\n",
    "                    print(f\"Imputed {col} using KNN (categorical variable)\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply advanced imputation\n",
    "df = apply_advanced_imputation(df, action_plan_df)\n",
    "\n",
    "# Check the result of the imputation\n",
    "missing_after_imputation = df.isna().sum()\n",
    "print(f\"Missing values after advanced imputation: {missing_after_imputation[missing_after_imputation > 0]}\")\n",
    "\n",
    "# Define output path for the cleaned dataset\n",
    "output_path = r\"C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\data\\interim\\advanced_imputed_data.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Advanced imputation complete and saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8741abf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after manual imputation: ethnicity                  5\n",
      "education_level            5\n",
      "bmi_value                  5\n",
      "bmi_category               5\n",
      "employment_status          5\n",
      "alcohol_consumption        5\n",
      "smoking_status_detail      5\n",
      "tumor_stage_roman        135\n",
      "dpyd_genotype_known        4\n",
      "dpyd_genotype_type        61\n",
      "chemo_schema_name          1\n",
      "chemo_schema_end_date      2\n",
      "chemo_cycles_n             2\n",
      "comorbidita              156\n",
      "data                     156\n",
      "adr_description          144\n",
      "adr_ctcae_grade          145\n",
      "adr_outcome              160\n",
      "adr_chemo_action         158\n",
      "adr_source_project       144\n",
      "adr_macro_category       144\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10064\\868906962.py:30: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  df.to_excel(output_path, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data after manual imputation has been saved to: C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\data\\interim\\manual_imputed_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a placeholder value for missing critical variables (e.g., \"Unknown\", \"Not Available\")\n",
    "critical_columns = [\n",
    "    'smoking_status_binary', 'tumor_diagnosis_date', 'oncology_unit_start_date', 'white_blood_cells_range', \n",
    "    'red_blood_cells_range', 'hemoglobin_range', 'neutrophils_percent_range', 'platelet_count_range', 'creatinine_range', \n",
    "    'ast_got_range', 'alt_gpt_range', 'total_bilirubin_range', 'direct_bilirubin_range', 'adr_left', 'blood_glucose_range', \n",
    "    'linea_trattamento_oncologico', 'comorbidity_category_list', 'altre_pat_n', 'adr_clean.1'\n",
    "]\n",
    "\n",
    "# Impute critical columns with placeholders if they have missing values\n",
    "for col in critical_columns:\n",
    "    if df[col].isna().sum() > 0:\n",
    "        if df[col].dtype == 'object':\n",
    "            # Impute with a placeholder for categorical columns\n",
    "            df[col] = df[col].fillna(\"Unknown\")\n",
    "            print(f\"Imputed {col} with placeholder 'Unknown'\")\n",
    "        elif df[col].dtype in ['int64', 'float64']:\n",
    "            # For numeric columns, we can impute with a reasonable placeholder like -1 or the median\n",
    "            df[col] = df[col].fillna(-1)  # Placeholder for numeric values\n",
    "            print(f\"Imputed {col} with placeholder -1 for numeric values\")\n",
    "\n",
    "# Check the result of imputation\n",
    "missing_after_imputation = df.isna().sum()\n",
    "print(f\"Missing values after manual imputation: {missing_after_imputation[missing_after_imputation > 0]}\")\n",
    "\n",
    "# Re-checking the data\n",
    "# Export the cleaned DataFrame with imputed values to Excel\n",
    "output_path = r\"C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\data\\interim\\manual_imputed_data.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Data after manual imputation has been saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0470923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed tumor_type with Unknown\n",
      "Imputed adr_ctcae_grade with 0\n",
      "Imputed adr_outcome with Not Available\n",
      "Imputed adr_chemo_action with None\n",
      "Imputed adr_source_project with Not Available\n",
      "Imputed adr_macro_category with No ADR\n",
      "Imputed comorbidita with No Comorbidity\n",
      "Imputed data with No Data\n",
      "Imputed chemo_schema_name with Not Available\n",
      "Imputed chemo_schema_start_date with 01/01/2020\n",
      "Imputed chemo_schema_end_date with 01/01/2020\n",
      "Imputed chemo_cycles_n with 0\n",
      "Imputed active_principle with None\n",
      "Imputed dose_reduced with No\n",
      "Imputed active_principles_n with 0\n",
      "Missing values after contextual imputation: ethnicity                  5\n",
      "education_level            5\n",
      "bmi_value                  5\n",
      "bmi_category               5\n",
      "employment_status          5\n",
      "alcohol_consumption        5\n",
      "smoking_status_detail      5\n",
      "tumor_stage_roman        135\n",
      "dpyd_genotype_known        4\n",
      "dpyd_genotype_type        61\n",
      "adr_description          144\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10064\\3502805109.py:42: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  df.to_excel(output_path, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data after contextual imputation has been saved to: C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\data\\interim\\contextual_imputed_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define a dictionary for domain-specific imputation\n",
    "domain_imputation = {\n",
    "    'tumor_type': 'Unknown',  # Tumor type missing, use placeholder 'Unknown'\n",
    "    'adr_adr': 'No ADR',  # Missing ADR, impute with 'No ADR'\n",
    "    'adr_onset_date': '01/01/2020',  # Missing ADR onset date, use placeholder date\n",
    "    'adr_ctcae_grade': 0,  # Missing ADR grade, impute with 0 or a default value\n",
    "    'adr_outcome': 'Not Available',  # Missing ADR outcome, impute with 'Not Available'\n",
    "    'adr_chemo_correlation': 'Unknown',  # Missing ADR chemo correlation, impute with 'Unknown'\n",
    "    'adr_chemo_action': 'None',  # Missing ADR chemo action, impute with 'None'\n",
    "    'adr_source_project': 'Not Available',  # Missing ADR source, impute with 'Not Available'\n",
    "    'adr_description_clean': 'No ADR',  # Missing ADR description, impute with 'No ADR'\n",
    "    'adr_macro_category': 'No ADR',  # Missing ADR macro category, impute with 'No ADR'\n",
    "    'comorbidita': 'No Comorbidity',  # Missing comorbidity, impute with 'No Comorbidity'\n",
    "    'comorbilita_cat': 'None',  # Missing comorbidity category, impute with 'None'\n",
    "    'altro': 'No Additional Info',  # Missing 'altro' info, impute with 'No Additional Info'\n",
    "    'data': 'No Data',  # Missing 'data', impute with 'No Data'\n",
    "    'treatment_line_n': 0,  # Missing treatment line count, impute with 0\n",
    "    'chemo_schema_name': 'Not Available',  # Missing chemotherapy schema name, impute with 'Not Available'\n",
    "    'chemo_schema_start_date': '01/01/2020',  # Missing chemotherapy start date, impute with placeholder\n",
    "    'chemo_schema_end_date': '01/01/2020',  # Missing chemotherapy end date, impute with placeholder\n",
    "    'chemo_cycles_n': 0,  # Missing chemotherapy cycles count, impute with 0\n",
    "    'active_principle': 'None',  # Missing active principle, impute with 'None'\n",
    "    'dose_reduced': 'No',  # Missing dose reduction info, impute with 'No'\n",
    "    'active_principles_n': 0  # Missing number of active principles, impute with 0\n",
    "}\n",
    "\n",
    "# Loop through the domain-imputation dictionary to apply imputation\n",
    "for col, value in domain_imputation.items():\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(value)\n",
    "        print(f\"Imputed {col} with {value}\")\n",
    "\n",
    "# Check the result of the imputation\n",
    "missing_after_imputation = df.isna().sum()\n",
    "print(f\"Missing values after contextual imputation: {missing_after_imputation[missing_after_imputation > 0]}\")\n",
    "\n",
    "# Export the cleaned DataFrame with imputed values to Excel\n",
    "output_path = r\"C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\data\\interim\\contextual_imputed_data.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Data after contextual imputation has been saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fcd18216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed observation_end_reason with Not Available\n",
      "Imputed tumor_stage_roman with Not Available\n",
      "Imputed dpyd_genotype_type with Not Tested\n",
      "Missing values after additional contextual imputation: ethnicity                  5\n",
      "education_level            5\n",
      "bmi_value                  5\n",
      "bmi_category               5\n",
      "employment_status          5\n",
      "alcohol_consumption        5\n",
      "smoking_status_detail      5\n",
      "dpyd_genotype_known        4\n",
      "adr_description          144\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10064\\1718418065.py:23: UserWarning: Pandas requires version '3.0.5' or newer of 'xlsxwriter' (version '3.0.3' currently installed).\n",
      "  df.to_excel(output_path, index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data after additional contextual imputation has been saved to: C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\data\\interim\\additional_contextual_imputed_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define a dictionary for further imputation for specific columns\n",
    "additional_imputation = {\n",
    "    'observation_end_reason': 'Not Available',  # Missing observation end reason, impute with 'Not Available'\n",
    "    'tumor_stage_roman': 'Not Available',  # Missing tumor stage roman, impute with 'Not Available'\n",
    "    'dpyd_genotype_type': 'Not Tested',  # Missing dpyd genotype type, impute with 'Not Tested'\n",
    "}\n",
    "\n",
    "# Loop through the additional imputation dictionary and apply imputation\n",
    "for col, value in additional_imputation.items():\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(value)\n",
    "        print(f\"Imputed {col} with {value}\")\n",
    "\n",
    "# Check the result of the imputation\n",
    "missing_after_imputation = df.isna().sum()\n",
    "print(f\"Missing values after additional contextual imputation: {missing_after_imputation[missing_after_imputation > 0]}\")\n",
    "\n",
    "# Export the cleaned DataFrame with imputed values to Excel\n",
    "output_path = r\"C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\data\\interim\\additional_contextual_imputed_data.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Data after additional contextual imputation has been saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a9268fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imputation summary has been saved to: C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\data\\raw\\imputation_summary.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a summary of the variables and imputation methods\n",
    "imputation_summary = []\n",
    "\n",
    "# For each column, summarize the imputation done\n",
    "for col in df.columns:\n",
    "    # Count missing values before imputation\n",
    "    missing_count = df[col].isna().sum()\n",
    "    \n",
    "    if missing_count > 0:  # Only consider columns with missing values\n",
    "        # Check the type of imputation that was done\n",
    "        if col in additional_imputation:  # Specific manual imputations\n",
    "            imputation_type = \"Placeholder\"\n",
    "            imputation_value = additional_imputation[col]\n",
    "        elif df[col].dtype == 'object':  # Categorical variables imputed with mode\n",
    "            imputation_type = \"Mode\"\n",
    "            imputation_value = df[col].mode()[0]\n",
    "        elif df[col].dtype in ['int64', 'float64']:  # Numeric variables imputed with median\n",
    "            imputation_type = \"Median\"\n",
    "            imputation_value = df[col].median()\n",
    "        else:\n",
    "            imputation_type = \"Unknown\"\n",
    "            imputation_value = \"N/A\"\n",
    "        \n",
    "        # Append to the summary list\n",
    "        imputation_summary.append({\n",
    "            'Variable': col,\n",
    "            'Missing Count': missing_count,\n",
    "            'Imputation Type': imputation_type,\n",
    "            'Imputation Value': imputation_value\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "imputation_summary_df = pd.DataFrame(imputation_summary)\n",
    "\n",
    "# Save to Excel\n",
    "imputation_summary_file = r\"C:\\Users\\HP\\OneDrive\\Desktop\\VERO_code\\Phase_1\\data\\raw\\imputation_summary.xlsx\"\n",
    "with pd.ExcelWriter(imputation_summary_file, engine=\"xlsxwriter\") as writer:\n",
    "    imputation_summary_df.to_excel(writer, sheet_name=\"Imputation Summary\", index=False)\n",
    "\n",
    "print(f\"✅ Imputation summary has been saved to: {imputation_summary_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e20567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
