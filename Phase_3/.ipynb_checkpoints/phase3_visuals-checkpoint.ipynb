{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84f47538",
   "metadata": {},
   "source": [
    "\n",
    "# Phase 3 - Extended Visualizations\n",
    "\n",
    "This notebook adds richer plots for the phenotypes.\n",
    "Inputs expected in `phase3_artifacts/`:\n",
    "- phase3_integrated_data.csv\n",
    "- cluster_labels.csv\n",
    "- gower_distance.npy\n",
    "- k_silhouette_scan.csv\n",
    "- pca_loadings.csv (optional)\n",
    "- umap_embeddings.csv or tsne_embeddings.csv (one of them is fine)\n",
    "\n",
    "It will create figures in `phase3_artifacts/figs`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bb8e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "BASE = Path(\"C:/Users/HP/OneDrive/Desktop/VERO_code/Phase_3\")\n",
    "ART  = BASE / \"phase3_outputs\n",
    "FIGS = ART / \"figs\"\n",
    "FIGS.mkdir(exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(ART / \"phase3_integrated_data.csv\")\n",
    "labels = pd.read_csv(ART / \"cluster_labels.csv\")[\"cluster\"].values\n",
    "\n",
    "print(\"Data shape:\", df.shape, \"Clusters:\", np.unique(labels, return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451e439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Embedding maps by cluster and by outcomes (size encoding)\n",
    "emb_df = None\n",
    "name = None\n",
    "if (ART / \"umap_embeddings.csv\").exists():\n",
    "    emb_df = pd.read_csv(ART / \"umap_embeddings.csv\")\n",
    "    name = \"UMAP\"\n",
    "elif (ART / \"tsne_embeddings.csv\").exists():\n",
    "    emb_df = pd.read_csv(ART / \"tsne_embeddings.csv\")\n",
    "    name = \"tSNE\"\n",
    "\n",
    "def find_cols(patterns):\n",
    "    out = []\n",
    "    for c in df.columns:\n",
    "        cl = c.lower()\n",
    "        if any(p in cl for p in patterns):\n",
    "            out.append(c)\n",
    "    return list(dict.fromkeys(out))\n",
    "\n",
    "if emb_df is not None:\n",
    "    # colored by cluster\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sc = plt.scatter(emb_df.iloc[:,0], emb_df.iloc[:,1], c=labels, s=14)\n",
    "    plt.xlabel(emb_df.columns[0]); plt.ylabel(emb_df.columns[1])\n",
    "    plt.title(f\"{name} by cluster\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGS / f\"{name.lower()}_by_cluster.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "    # size by a binary outcome if available\n",
    "    cand_bin = find_cols([\"readmission\",\"adr\",\"toxicity\",\"frailty\",\"mortality\",\"death\",\"event\"])\n",
    "    if cand_bin:\n",
    "        col = cand_bin[0]\n",
    "        vals = pd.Series(df[col]).fillna(0).astype(int).values\n",
    "        sizes = np.where(vals==1, 24, 8)\n",
    "        plt.figure(figsize=(6,5))\n",
    "        plt.scatter(emb_df.iloc[:,0], emb_df.iloc[:,1], s=sizes)\n",
    "        plt.xlabel(emb_df.columns[0]); plt.ylabel(emb_df.columns[1])\n",
    "        plt.title(f\"{name} marker size by {col} (1 larger)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FIGS / f\"{name.lower()}_size_{col}.png\", dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "    # size by a continuous outcome if available\n",
    "    cand_cont = find_cols([\"frailty_score\",\"risk_index\",\"survival_time\",\"time_to_event\"])\n",
    "    if cand_cont:\n",
    "        col = cand_cont[0]\n",
    "        v = pd.Series(df[col]).to_numpy()\n",
    "        if np.nanmax(v) > np.nanmin(v):\n",
    "            s = 8 + 22*(v - np.nanmin(v)) / (np.nanmax(v) - np.nanmin(v))\n",
    "        else:\n",
    "            s = np.full_like(v, 10)\n",
    "        plt.figure(figsize=(6,5))\n",
    "        plt.scatter(emb_df.iloc[:,0], emb_df.iloc[:,1], s=s)\n",
    "        plt.xlabel(emb_df.columns[0]); plt.ylabel(emb_df.columns[1])\n",
    "        plt.title(f\"{name} marker size by {col}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FIGS / f\"{name.lower()}_size_{col}_cont.png\", dpi=150)\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No embedding CSV found. Skipping embedding plots.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75083d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Silhouette plot for the best k\n",
    "KSCAN = ART / \"k_silhouette_scan.csv\"\n",
    "GOWER = ART / \"gower_distance.npy\"\n",
    "\n",
    "if KSCAN.exists() and GOWER.exists():\n",
    "    ks = pd.read_csv(KSCAN).sort_values(\"silhouette\", ascending=False)\n",
    "    best_k = int(ks.iloc[0][\"k\"])\n",
    "    D = np.load(GOWER)\n",
    "\n",
    "    def square_to_condensed(square):\n",
    "        idx = np.triu_indices_from(square, k=1)\n",
    "        return square[idx]\n",
    "\n",
    "    from sklearn.metrics import silhouette_samples\n",
    "    Z = linkage(square_to_condensed(D), method=\"average\")\n",
    "    lab = fcluster(Z, best_k, criterion=\"maxclust\")\n",
    "    sil_vals = silhouette_samples(D, lab, metric=\"precomputed\")\n",
    "\n",
    "    plt.figure(figsize=(7,4))\n",
    "    y_lower = 10\n",
    "    for i in sorted(np.unique(lab)):\n",
    "        ith = sil_vals[lab == i]\n",
    "        ith.sort()\n",
    "        size = ith.shape[0]\n",
    "        y_upper = y_lower + size\n",
    "        plt.fill_betweenx(np.arange(y_lower, y_upper), 0, ith)\n",
    "        y_lower = y_upper + 10\n",
    "    plt.axvline(np.mean(sil_vals), linestyle=\"--\")\n",
    "    plt.xlabel(\"Silhouette coefficient\")\n",
    "    plt.ylabel(\"Samples grouped by cluster\")\n",
    "    plt.title(f\"Silhouette plot (k={best_k})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGS / \"silhouette_plot.png\", dpi=150)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"k_silhouette_scan.csv or gower_distance.npy missing. Skipping silhouette plot.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a269235",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Dendrogram from the Gower distance\n",
    "GOWER = ART / \"gower_distance.npy\"\n",
    "if GOWER.exists():\n",
    "    D = np.load(GOWER)\n",
    "\n",
    "    def square_to_condensed(square):\n",
    "        idx = np.triu_indices_from(square, k=1)\n",
    "        return square[idx]\n",
    "\n",
    "    Z = linkage(square_to_condensed(D), method=\"average\")\n",
    "    plt.figure(figsize=(8,4))\n",
    "    dendrogram(Z, no_labels=True, color_threshold=0.0)\n",
    "    plt.title(\"Hierarchical dendrogram (average linkage)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGS / \"dendrogram.png\", dpi=150)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"gower_distance.npy missing. Skipping dendrogram.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c3529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Distance heatmap ordered by cluster\n",
    "GOWER = ART / \"gower_distance.npy\"\n",
    "if GOWER.exists():\n",
    "    D = np.load(GOWER)\n",
    "    order = np.argsort(labels)\n",
    "    D_ord = D[np.ix_(order, order)]\n",
    "    plt.figure(figsize=(6,5))\n",
    "    im = plt.imshow(D_ord, cmap=\"viridis\")\n",
    "    plt.title(\"Gower distance heatmap (ordered by cluster)\")\n",
    "    plt.colorbar(im)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGS / \"gower_heatmap_by_cluster.png\", dpi=150)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"gower_distance.npy missing. Skipping heatmap.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30001c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) PCA biplot from loadings (if available)\n",
    "LOAD = ART / \"pca_loadings.csv\"\n",
    "if LOAD.exists():\n",
    "    loadings = pd.read_csv(LOAD)\n",
    "    if loadings.shape[0] >= 2:\n",
    "        pc1 = loadings.iloc[0].values\n",
    "        pc2 = loadings.iloc[1].values\n",
    "        feats = loadings.columns.tolist()\n",
    "\n",
    "        plt.figure(figsize=(7,6))\n",
    "        plt.axhline(0, color=\"k\", linewidth=0.5)\n",
    "        plt.axvline(0, color=\"k\", linewidth=0.5)\n",
    "        for i, f in enumerate(feats):\n",
    "            plt.arrow(0, 0, pc1[i], pc2[i], head_width=0.02, length_includes_head=True)\n",
    "            if i % max(1, len(feats)//20) == 0:\n",
    "                plt.text(pc1[i]*1.1, pc2[i]*1.1, f, fontsize=7)\n",
    "        plt.xlabel(\"PC1 loading\")\n",
    "        plt.ylabel(\"PC2 loading\")\n",
    "        plt.title(\"PCA biplot (loadings)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FIGS / \"pca_biplot_loadings.png\", dpi=150)\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"pca_loadings.csv not found. Skipping biplot.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51ddb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6) Cluster profile heatmap. Top numeric features by between-cluster variance.\n",
    "num_cols = [c for c in df.columns if c != \"cluster\" and pd.api.types.is_numeric_dtype(df[c])]\n",
    "if num_cols:\n",
    "    bc = []\n",
    "    for c in num_cols:\n",
    "        means = df.groupby(\"cluster\")[c].mean()\n",
    "        bc.append((c, np.nanvar(means.values)))\n",
    "    top = sorted(bc, key=lambda x: x[1], reverse=True)[:20]\n",
    "    top_feats = [t[0] for t in top]\n",
    "\n",
    "    prof = df.groupby(\"cluster\")[top_feats].mean()\n",
    "    prof = (prof - prof.min()) / (prof.max() - prof.min()).replace([np.inf, -np.inf], 0).fillna(0)\n",
    "\n",
    "    plt.figure(figsize=(max(8, len(top_feats)/2), 5))\n",
    "    im = plt.imshow(prof.values, aspect=\"auto\", cmap=\"magma\")\n",
    "    plt.yticks(ticks=range(prof.shape[0]), labels=prof.index.tolist())\n",
    "    plt.xticks(ticks=range(prof.shape[1]), labels=prof.columns.tolist(), rotation=60, ha=\"right\")\n",
    "    plt.title(\"Cluster profiles (scaled means of top variance features)\")\n",
    "    plt.colorbar(im)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGS / \"cluster_profile_heatmap.png\", dpi=150)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No numeric features found for profile heatmap.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7) Outcome separation quick visuals. Up to four binary and four continuous.\n",
    "def find_cols(patterns):\n",
    "    out = []\n",
    "    for c in df.columns:\n",
    "        cl = c.lower()\n",
    "        if any(p in cl for p in patterns):\n",
    "            out.append(c)\n",
    "    return list(dict.fromkeys(out))\n",
    "\n",
    "cand_bin = find_cols([\"readmission\",\"adr\",\"toxicity\",\"frailty\",\"mortality\",\"death\",\"event\"])\n",
    "cand_cont = find_cols([\"frailty_score\",\"risk_index\",\"survival_time\",\"time_to_event\"])\n",
    "\n",
    "for c in cand_bin[:4]:\n",
    "    if set(pd.Series(df[c]).dropna().unique()).issubset({0,1}):\n",
    "        rate = df.groupby(\"cluster\")[c].mean()\n",
    "        plt.figure(figsize=(5,3))\n",
    "        plt.bar(rate.index.astype(str), rate.values)\n",
    "        plt.title(f\"Rate by cluster - {c}\")\n",
    "        plt.ylabel(\"Rate\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FIGS / f\"rate_by_cluster__{c}.png\", dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "for c in cand_cont[:4]:\n",
    "    if pd.api.types.is_numeric_dtype(df[c]):\n",
    "        plt.figure(figsize=(6,4))\n",
    "        bins = 20\n",
    "        for cl in sorted(np.unique(labels)):\n",
    "            v = pd.Series(df[df[\"cluster\"]==cl][c]).dropna().values\n",
    "            if len(v) > 0:\n",
    "                plt.hist(v, bins=bins, alpha=0.5, label=f\"C{cl}\")\n",
    "        plt.legend()\n",
    "        plt.title(f\"Distribution by cluster - {c}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FIGS / f\"dist_by_cluster__{c}.png\", dpi=150)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4820d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8) Print stability summary if present\n",
    "stab = ART / \"stability_report.txt\"\n",
    "if stab.exists():\n",
    "    print(stab.read_text(encoding=\"utf-8\"))\n",
    "else:\n",
    "    print(\"stability_report.txt not found. Run stability step in phenotyping notebook to produce it.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
